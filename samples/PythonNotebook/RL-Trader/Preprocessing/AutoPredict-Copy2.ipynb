{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../Data/Indicator_based_RL/indicator_dataset.csv | Columns = 284 / 284 | Rows = 503452 -> 503452\n"
     ]
    }
   ],
   "source": [
    "data= task.Dataset(file_path = '../Data/Indicator_based_RL/indicator_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:int(len(data) * 0.5), :-24]\n",
    "test = data.iloc[int(len(data) * 0.5):, :-24]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../Data/Label_based_RL/new_labels.csv | Columns = 21 / 21 | Rows = 503452 -> 503452\n"
     ]
    }
   ],
   "source": [
    "targets = task.Dataset(file_path = '../Data/Label_based_RL/new_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peaks_0.5</th>\n",
       "      <th>valleys_0.5</th>\n",
       "      <th>peaks_0.25</th>\n",
       "      <th>valleys_0.25</th>\n",
       "      <th>peaks_1</th>\n",
       "      <th>valleys_1</th>\n",
       "      <th>peaks_2</th>\n",
       "      <th>valleys_2</th>\n",
       "      <th>label_0.25</th>\n",
       "      <th>reversed_label_0.25</th>\n",
       "      <th>...</th>\n",
       "      <th>reversed_label_0.5</th>\n",
       "      <th>label_1</th>\n",
       "      <th>reversed_label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>reversed_label_2</th>\n",
       "      <th>reg_labels_0.25</th>\n",
       "      <th>reg_labels_0.5</th>\n",
       "      <th>reg_labels_1</th>\n",
       "      <th>reg_labels_2</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>3.53</td>\n",
       "      <td>16.56</td>\n",
       "      <td>135.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>3.64</td>\n",
       "      <td>16.67</td>\n",
       "      <td>135.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>3.42</td>\n",
       "      <td>16.45</td>\n",
       "      <td>135.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>136.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>1.40</td>\n",
       "      <td>14.43</td>\n",
       "      <td>137.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   peaks_0.5  valleys_0.5  peaks_0.25  valleys_0.25  peaks_1  valleys_1  \\\n",
       "0          0            0           0             0        0          0   \n",
       "1          1            0           1             0        1          0   \n",
       "2          1            0           1             0        1          0   \n",
       "3          1            0           1             0        1          0   \n",
       "4          0            1           0             1        0          0   \n",
       "\n",
       "   peaks_2  valleys_2  label_0.25  reversed_label_0.25  ...  \\\n",
       "0        0          0           1                    0  ...   \n",
       "1        1          0           1                    0  ...   \n",
       "2        1          0           1                    0  ...   \n",
       "3        1          0           1                    0  ...   \n",
       "4        0          0           0                    1  ...   \n",
       "\n",
       "   reversed_label_0.5  label_1  reversed_label_1  label_2  reversed_label_2  \\\n",
       "0                   0        1                 0        1                 0   \n",
       "1                   0        1                 0        1                 0   \n",
       "2                   0        1                 0        1                 0   \n",
       "3                   0        1                 0        1                 0   \n",
       "4                   1        1                 0        1                 0   \n",
       "\n",
       "   reg_labels_0.25  reg_labels_0.5  reg_labels_1  reg_labels_2   price  \n",
       "0             2.13            2.13          3.53         16.56  135.38  \n",
       "1             2.24            2.24          3.64         16.67  135.27  \n",
       "2             2.02            2.02          3.42         16.45  135.49  \n",
       "3             1.22            1.22          3.10          3.10  136.29  \n",
       "4            -0.64           -1.09          1.40         14.43  137.51  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'reversed_label'\n",
    "coeff = '2'\n",
    "\n",
    "label_column = '{}_{}'.format(label_type, coeff)\n",
    "targets = targets[label_column]\n",
    "train_targets = targets[:int(len(targets) * 0.5)]\n",
    "test_targets = targets[int(len(targets) * 0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[label_column] = train_targets\n",
    "test[label_column] = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20201015_210426/\n",
      "Beginning AutoGluon training ... Time limit = 4320.0s\n",
      "AutoGluon will save models to AutogluonModels/ag-20201015_210426/\n",
      "AutoGluon Version:  0.0.14\n",
      "Train Data Rows:    251726\n",
      "Train Data Columns: 260\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    86769.26 MB\n",
      "\tTrain Data (Original)  Memory Usage: 523.59 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['KICKINGBYLENGTH', 'KICKING', 'ABANDONEDBABY']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 196 | ['price', 'volume', 'bar:open', 'bar:low', 'bar:high', ...]\n",
      "\t\t('int', [])   :  61 | ['time', 'AROON5050', 'AROON100100', 'UPDOWNGAPTHREEMETHODS', 'UPSIDEGAPTWOCROWS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 196 | ['price', 'volume', 'bar:open', 'bar:low', 'bar:high', ...]\n",
      "\t\t('int', [])   :  61 | ['time', 'AROON5050', 'AROON100100', 'UPDOWNGAPTHREEMETHODS', 'UPSIDEGAPTWOCROWS', ...]\n",
      "\t10.3s = Fit runtime\n",
      "\t257 features in original data used to generate 257 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 517.55 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 10.79s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'average_precision'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'average_precision'\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ... Training model for up to 2154.6s of the 4309.2s of remaining time.\n",
      "\t0.9999\t = Validation average_precision score\n",
      "\t1680.83s\t = Training runtime\n",
      "\t24.36s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ... Training model for up to 438.12s of the 2592.72s of remaining time.\n",
      "\tTime limit exceeded... Skipping RandomForestClassifierEntr_STACKER_l0.\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ... Training model for up to 240.71s of the 2395.31s of remaining time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesClassifierGini_STACKER_l0.\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ... Training model for up to 179.24s of the 2333.83s of remaining time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesClassifierEntr_STACKER_l0.\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ... Training model for up to 145.01s of the 2299.61s of remaining time.\n",
      "\tTime limit exceeded... Skipping KNeighborsClassifierUnif_STACKER_l0.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: weighted_ensemble_k0_l1 ... Training model for up to 360.0s of the 1905.83s of remaining time.\n",
      "\t0.9999\t = Validation average_precision score\n",
      "\t0.09s\t = Training runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l1 ... Training model for up to 1905.19s of the 1904.94s of remaining time.\n",
      "\t0.9999\t = Validation average_precision score\n",
      "\t1554.99s\t = Training runtime\n",
      "\t16.01s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l1 ... Training model for up to 313.69s of the 313.44s of remaining time.\n",
      "\tTime limit exceeded... Skipping RandomForestClassifierEntr_STACKER_l1.\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l1 ... Training model for up to 209.74s of the 209.49s of remaining time.\n",
      "\t0.9999\t = Validation average_precision score\n",
      "\t179.18s\t = Training runtime\n",
      "\t7.69s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l1 ... Training model for up to 16.06s of the 15.81s of remaining time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesClassifierEntr_STACKER_l1.\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l1 ... Training model for up to 1.46s of the 1.21s of remaining time.\n",
      "\tTime limit exceeded... Skipping KNeighborsClassifierUnif_STACKER_l1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: weighted_ensemble_k0_l2 ... Training model for up to 360.0s of the -222.32s of remaining time.\n",
      "\t0.9999\t = Validation average_precision score\n",
      "\t11.14s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4554.98s ...\n"
     ]
    }
   ],
   "source": [
    "time_limits = 1.2 * 60 *60\n",
    "predictor = task.fit(train_data=train, label=label_column, time_limits=time_limits, presets='best_quality', eval_metric='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: average_precision on test data: 0.5855954123215514\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"average_precision\": 0.5855954123215514\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "perf = predictor.evaluate_predictions(y_true=test_targets, y_pred=prediction, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savetxt('predictions_{}_{}.csv'.format(label_type, coeff), prediction, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5635889816705465"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test[label_column])/len(test[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market_predictor",
   "language": "python",
   "name": "market_predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
