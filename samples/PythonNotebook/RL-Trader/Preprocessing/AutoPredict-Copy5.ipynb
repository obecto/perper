{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../Data/Indicator_based_RL/indicator_dataset.csv | Columns = 284 / 284 | Rows = 503452 -> 503452\n"
     ]
    }
   ],
   "source": [
    "data= task.Dataset(file_path = '../Data/Indicator_based_RL/indicator_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:int(len(data) * 0.5), :-24]\n",
    "test = data.iloc[int(len(data) * 0.5):, :-24]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../Data/Label_based_RL/new_labels.csv | Columns = 21 / 21 | Rows = 503452 -> 503452\n"
     ]
    }
   ],
   "source": [
    "targets = task.Dataset(file_path = '../Data/Label_based_RL/new_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peaks_0.5</th>\n",
       "      <th>valleys_0.5</th>\n",
       "      <th>peaks_0.25</th>\n",
       "      <th>valleys_0.25</th>\n",
       "      <th>peaks_1</th>\n",
       "      <th>valleys_1</th>\n",
       "      <th>peaks_2</th>\n",
       "      <th>valleys_2</th>\n",
       "      <th>label_0.25</th>\n",
       "      <th>reversed_label_0.25</th>\n",
       "      <th>...</th>\n",
       "      <th>reversed_label_0.5</th>\n",
       "      <th>label_1</th>\n",
       "      <th>reversed_label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>reversed_label_2</th>\n",
       "      <th>reg_labels_0.25</th>\n",
       "      <th>reg_labels_0.5</th>\n",
       "      <th>reg_labels_1</th>\n",
       "      <th>reg_labels_2</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>3.53</td>\n",
       "      <td>16.56</td>\n",
       "      <td>135.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>3.64</td>\n",
       "      <td>16.67</td>\n",
       "      <td>135.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>3.42</td>\n",
       "      <td>16.45</td>\n",
       "      <td>135.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>136.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>1.40</td>\n",
       "      <td>14.43</td>\n",
       "      <td>137.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   peaks_0.5  valleys_0.5  peaks_0.25  valleys_0.25  peaks_1  valleys_1  \\\n",
       "0          0            0           0             0        0          0   \n",
       "1          1            0           1             0        1          0   \n",
       "2          1            0           1             0        1          0   \n",
       "3          1            0           1             0        1          0   \n",
       "4          0            1           0             1        0          0   \n",
       "\n",
       "   peaks_2  valleys_2  label_0.25  reversed_label_0.25  ...  \\\n",
       "0        0          0           1                    0  ...   \n",
       "1        1          0           1                    0  ...   \n",
       "2        1          0           1                    0  ...   \n",
       "3        1          0           1                    0  ...   \n",
       "4        0          0           0                    1  ...   \n",
       "\n",
       "   reversed_label_0.5  label_1  reversed_label_1  label_2  reversed_label_2  \\\n",
       "0                   0        1                 0        1                 0   \n",
       "1                   0        1                 0        1                 0   \n",
       "2                   0        1                 0        1                 0   \n",
       "3                   0        1                 0        1                 0   \n",
       "4                   1        1                 0        1                 0   \n",
       "\n",
       "   reg_labels_0.25  reg_labels_0.5  reg_labels_1  reg_labels_2   price  \n",
       "0             2.13            2.13          3.53         16.56  135.38  \n",
       "1             2.24            2.24          3.64         16.67  135.27  \n",
       "2             2.02            2.02          3.42         16.45  135.49  \n",
       "3             1.22            1.22          3.10          3.10  136.29  \n",
       "4            -0.64           -1.09          1.40         14.43  137.51  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'peaks'\n",
    "coeff = '0.25'\n",
    "\n",
    "label_column = '{}_{}'.format(label_type, coeff)\n",
    "targets = targets[label_column]\n",
    "train_targets = targets[:int(len(targets) * 0.5)]\n",
    "test_targets = targets[int(len(targets) * 0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[label_column] = train_targets\n",
    "test[label_column] = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20201016_115950/\n",
      "Beginning AutoGluon training ... Time limit = 4320.0s\n",
      "AutoGluon will save models to AutogluonModels/ag-20201016_115950/\n",
      "AutoGluon Version:  0.0.14\n",
      "Train Data Rows:    251726\n",
      "Train Data Columns: 260\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    80848.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 523.59 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['KICKINGBYLENGTH', 'KICKING', 'ABANDONEDBABY']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 196 | ['price', 'volume', 'bar:open', 'bar:low', 'bar:high', ...]\n",
      "\t\t('int', [])   :  61 | ['time', 'AROON5050', 'AROON100100', 'UPDOWNGAPTHREEMETHODS', 'UPSIDEGAPTWOCROWS', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 196 | ['price', 'volume', 'bar:open', 'bar:low', 'bar:high', ...]\n",
      "\t\t('int', [])   :  61 | ['time', 'AROON5050', 'AROON100100', 'UPDOWNGAPTHREEMETHODS', 'UPSIDEGAPTWOCROWS', ...]\n",
      "\t6.7s = Fit runtime\n",
      "\t257 features in original data used to generate 257 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 517.55 MB (0.7% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 7.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'average_precision'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'average_precision'\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ... Training model for up to 2156.36s of the 4312.73s of remaining time.\n",
      "\t0.6017\t = Validation average_precision score\n",
      "\t979.64s\t = Training runtime\n",
      "\t8.12s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ... Training model for up to 1154.25s of the 3310.61s of remaining time.\n",
      "\tTime limit exceeded... Skipping RandomForestClassifierEntr_STACKER_l0.\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ... Training model for up to 1016.28s of the 3172.65s of remaining time.\n",
      "\t0.6111\t = Validation average_precision score\n",
      "\t259.52s\t = Training runtime\n",
      "\t9.93s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ... Training model for up to 713.48s of the 2869.84s of remaining time.\n",
      "\t0.6159\t = Validation average_precision score\n",
      "\t253.71s\t = Training runtime\n",
      "\t8.24s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ... Training model for up to 420.5s of the 2576.86s of remaining time.\n",
      "\tTime limit exceeded... Skipping KNeighborsClassifierUnif_STACKER_l0.\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ... Training model for up to 300.34s of the 2456.71s of remaining time.\n",
      "\tTime limit exceeded... Skipping KNeighborsClassifierDist_STACKER_l0.\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ... Training model for up to 178.96s of the 2335.32s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 60. Best iteration is:\n",
      "\t[60]\ttrain_set's binary_logloss: 0.416525\ttrain_set's average_precision: 0.348723\tvalid_set's binary_logloss: 0.423846\tvalid_set's average_precision: 0.314453\n",
      "\tRan out of time, early stopping on iteration 69. Best iteration is:\n",
      "\t[69]\ttrain_set's binary_logloss: 0.413112\ttrain_set's average_precision: 0.364105\tvalid_set's binary_logloss: 0.425968\tvalid_set's average_precision: 0.303473\n",
      "\tRan out of time, early stopping on iteration 83. Best iteration is:\n",
      "\t[83]\ttrain_set's binary_logloss: 0.408936\ttrain_set's average_precision: 0.383147\tvalid_set's binary_logloss: 0.423787\tvalid_set's average_precision: 0.307413\n",
      "\tRan out of time, early stopping on iteration 94. Best iteration is:\n",
      "\t[94]\ttrain_set's binary_logloss: 0.406027\ttrain_set's average_precision: 0.396392\tvalid_set's binary_logloss: 0.420769\tvalid_set's average_precision: 0.326187\n",
      "\tRan out of time, early stopping on iteration 116. Best iteration is:\n",
      "\t[116]\ttrain_set's binary_logloss: 0.40075\ttrain_set's average_precision: 0.424459\tvalid_set's binary_logloss: 0.4188\tvalid_set's average_precision: 0.32883\n",
      "\tRan out of time, early stopping on iteration 64. Best iteration is:\n",
      "\t[64]\ttrain_set's binary_logloss: 0.415023\ttrain_set's average_precision: 0.354631\tvalid_set's binary_logloss: 0.426815\tvalid_set's average_precision: 0.297377\n",
      "\tRan out of time, early stopping on iteration 134. Best iteration is:\n",
      "\t[134]\ttrain_set's binary_logloss: 0.395418\ttrain_set's average_precision: 0.446488\tvalid_set's binary_logloss: 0.416796\tvalid_set's average_precision: 0.333822\n",
      "\tRan out of time, early stopping on iteration 44. Best iteration is:\n",
      "\t[44]\ttrain_set's binary_logloss: 0.421334\ttrain_set's average_precision: 0.328325\tvalid_set's binary_logloss: 0.431326\tvalid_set's average_precision: 0.283495\n",
      "\tRan out of time, early stopping on iteration 57. Best iteration is:\n",
      "\t[57]\ttrain_set's binary_logloss: 0.417044\ttrain_set's average_precision: 0.347768\tvalid_set's binary_logloss: 0.427178\tvalid_set's average_precision: 0.302513\n",
      "\tRan out of time, early stopping on iteration 108. Best iteration is:\n",
      "\t[108]\ttrain_set's binary_logloss: 0.401993\ttrain_set's average_precision: 0.41491\tvalid_set's binary_logloss: 0.420451\tvalid_set's average_precision: 0.321744\n",
      "\t0.3116\t = Validation average_precision score\n",
      "\t172.74s\t = Training runtime\n",
      "\t0.97s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT_STACKER_l0 ... Training model for up to 5.01s of the 2161.38s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\ttrain_set's binary_logloss: 0.45206\ttrain_set's average_precision: 0.248588\tvalid_set's binary_logloss: 0.451948\tvalid_set's average_precision: 0.253097\n",
      "\tTime limit exceeded... Skipping LightGBMClassifierXT_STACKER_l0.\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ... Training model for up to 2.1s of the 2158.46s of remaining time.\n",
      "\tTime limit exceeded... Skipping CatboostClassifier_STACKER_l0.\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ... Training model for up to 0.26s of the 2156.62s of remaining time.\n",
      "\tRan out of time, stopping training early.\n",
      "\tTime limit exceeded... Skipping NeuralNetClassifier_STACKER_l0.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: weighted_ensemble_k0_l1 ... Training model for up to 360.0s of the 2106.93s of remaining time.\n",
      "\t0.6181\t = Validation average_precision score\n",
      "\t20.27s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l1 ... Training model for up to 2086.25s of the 2086.08s of remaining time.\n",
      "\t0.6524\t = Validation average_precision score\n",
      "\t852.46s\t = Training runtime\n",
      "\t10.57s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l1 ... Training model for up to 1212.49s of the 1212.32s of remaining time.\n",
      "\t0.6532\t = Validation average_precision score\n",
      "\t1076.01s\t = Training runtime\n",
      "\t8.24s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l1 ... Training model for up to 117.73s of the 117.56s of remaining time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesClassifierGini_STACKER_l1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l1 ... Training model for up to 87.63s of the 87.46s of remaining time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesClassifierEntr_STACKER_l1.\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l1 ... Training model for up to 58.43s of the 58.26s of remaining time.\n",
      "\tTime limit exceeded... Skipping KNeighborsClassifierUnif_STACKER_l1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: weighted_ensemble_k0_l2 ... Training model for up to 360.0s of the -62.66s of remaining time.\n",
      "\t0.6557\t = Validation average_precision score\n",
      "\t12.8s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4396.94s ...\n"
     ]
    }
   ],
   "source": [
    "time_limits = 1.2 * 60 *60\n",
    "predictor = task.fit(train_data=train, label=label_column, time_limits=time_limits, presets='best_quality', eval_metric='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: average_precision on test data: 0.16998403207158636\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"average_precision\": 0.16998403207158636\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "perf = predictor.evaluate_predictions(y_true=test_targets, y_pred=prediction, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savetxt('predictions_{}_{}.csv'.format(label_type, coeff), prediction, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15673788166498495"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test[label_column])/len(test[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market_predictor",
   "language": "python",
   "name": "market_predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
