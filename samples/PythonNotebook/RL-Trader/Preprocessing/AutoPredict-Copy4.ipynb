{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon import TabularPrediction as task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../Data/Indicator_based_RL/indicator_dataset.csv | Columns = 284 / 284 | Rows = 503452 -> 503452\n"
     ]
    }
   ],
   "source": [
    "data= task.Dataset(file_path = '../Data/Indicator_based_RL/indicator_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:int(len(data) * 0.5), 1:-25]\n",
    "test = data.iloc[int(len(data) * 0.5):, 1:-25]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ../Data/Label_based_RL/new_labels.csv | Columns = 21 / 21 | Rows = 503452 -> 503452\n"
     ]
    }
   ],
   "source": [
    "targets = task.Dataset(file_path = '../Data/Label_based_RL/new_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peaks_0.5</th>\n",
       "      <th>valleys_0.5</th>\n",
       "      <th>peaks_0.25</th>\n",
       "      <th>valleys_0.25</th>\n",
       "      <th>peaks_1</th>\n",
       "      <th>valleys_1</th>\n",
       "      <th>peaks_2</th>\n",
       "      <th>valleys_2</th>\n",
       "      <th>label_0.25</th>\n",
       "      <th>reversed_label_0.25</th>\n",
       "      <th>...</th>\n",
       "      <th>reversed_label_0.5</th>\n",
       "      <th>label_1</th>\n",
       "      <th>reversed_label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>reversed_label_2</th>\n",
       "      <th>reg_labels_0.25</th>\n",
       "      <th>reg_labels_0.5</th>\n",
       "      <th>reg_labels_1</th>\n",
       "      <th>reg_labels_2</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.13</td>\n",
       "      <td>3.53</td>\n",
       "      <td>16.56</td>\n",
       "      <td>135.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.24</td>\n",
       "      <td>3.64</td>\n",
       "      <td>16.67</td>\n",
       "      <td>135.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.02</td>\n",
       "      <td>3.42</td>\n",
       "      <td>16.45</td>\n",
       "      <td>135.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>136.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>1.40</td>\n",
       "      <td>14.43</td>\n",
       "      <td>137.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   peaks_0.5  valleys_0.5  peaks_0.25  valleys_0.25  peaks_1  valleys_1  \\\n",
       "0          0            0           0             0        0          0   \n",
       "1          1            0           1             0        1          0   \n",
       "2          1            0           1             0        1          0   \n",
       "3          1            0           1             0        1          0   \n",
       "4          0            1           0             1        0          0   \n",
       "\n",
       "   peaks_2  valleys_2  label_0.25  reversed_label_0.25  ...  \\\n",
       "0        0          0           1                    0  ...   \n",
       "1        1          0           1                    0  ...   \n",
       "2        1          0           1                    0  ...   \n",
       "3        1          0           1                    0  ...   \n",
       "4        0          0           0                    1  ...   \n",
       "\n",
       "   reversed_label_0.5  label_1  reversed_label_1  label_2  reversed_label_2  \\\n",
       "0                   0        1                 0        1                 0   \n",
       "1                   0        1                 0        1                 0   \n",
       "2                   0        1                 0        1                 0   \n",
       "3                   0        1                 0        1                 0   \n",
       "4                   1        1                 0        1                 0   \n",
       "\n",
       "   reg_labels_0.25  reg_labels_0.5  reg_labels_1  reg_labels_2   price  \n",
       "0             2.13            2.13          3.53         16.56  135.38  \n",
       "1             2.24            2.24          3.64         16.67  135.27  \n",
       "2             2.02            2.02          3.42         16.45  135.49  \n",
       "3             1.22            1.22          3.10          3.10  136.29  \n",
       "4            -0.64           -1.09          1.40         14.43  137.51  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'label'\n",
    "coeff = '0.5'\n",
    "\n",
    "label_column = '{}_{}'.format(label_type, coeff)\n",
    "targets = targets[label_column]\n",
    "train_targets = targets[:int(len(targets) * 0.5)]\n",
    "test_targets = targets[int(len(targets) * 0.5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[label_column] = train_targets\n",
    "test[label_column] = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20201016_120038/\n",
      "Beginning AutoGluon training ... Time limit = 4320.0s\n",
      "AutoGluon will save models to AutogluonModels/ag-20201016_120038/\n",
      "AutoGluon Version:  0.0.14\n",
      "Train Data Rows:    251726\n",
      "Train Data Columns: 258\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    80144.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 519.56 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['KICKINGBYLENGTH', 'KICKING', 'ABANDONEDBABY']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 196 | ['price', 'volume', 'bar:open', 'bar:low', 'bar:high', ...]\n",
      "\t\t('int', [])   :  59 | ['AROON5050', 'AROON100100', 'UPDOWNGAPTHREEMETHODS', 'UPSIDEGAPTWOCROWS', 'UNIQUETHREERIVER', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 196 | ['price', 'volume', 'bar:open', 'bar:low', 'bar:high', ...]\n",
      "\t\t('int', [])   :  59 | ['AROON5050', 'AROON100100', 'UPDOWNGAPTHREEMETHODS', 'UPSIDEGAPTWOCROWS', 'UNIQUETHREERIVER', ...]\n",
      "\t9.2s = Fit runtime\n",
      "\t255 features in original data used to generate 255 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 513.52 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 9.79s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'average_precision'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'average_precision'\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ... Training model for up to 2155.11s of the 4310.21s of remaining time.\n",
      "\t0.9983\t = Validation average_precision score\n",
      "\t703.22s\t = Training runtime\n",
      "\t6.86s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ... Training model for up to 1435.48s of the 3590.58s of remaining time.\n",
      "\t0.9984\t = Validation average_precision score\n",
      "\t1079.95s\t = Training runtime\n",
      "\t6.54s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ... Training model for up to 340.86s of the 2495.96s of remaining time.\n",
      "\t0.9977\t = Validation average_precision score\n",
      "\t159.52s\t = Training runtime\n",
      "\t4.37s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ... Training model for up to 153.95s of the 2309.05s of remaining time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesClassifierEntr_STACKER_l0.\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ... Training model for up to 136.33s of the 2291.43s of remaining time.\n",
      "\tTime limit exceeded... Skipping KNeighborsClassifierUnif_STACKER_l0.\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ... Training model for up to 55.6s of the 2210.71s of remaining time.\n",
      "\tTime limit exceeded... Skipping KNeighborsClassifierDist_STACKER_l0.\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ... Training model for up to 44.25s of the 2199.35s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 19. Best iteration is:\n",
      "\t[19]\ttrain_set's binary_logloss: 0.619446\ttrain_set's average_precision: 0.800397\tvalid_set's binary_logloss: 0.621666\tvalid_set's average_precision: 0.791809\n",
      "\tRan out of time, early stopping on iteration 22. Best iteration is:\n",
      "\t[22]\ttrain_set's binary_logloss: 0.611758\ttrain_set's average_precision: 0.816412\tvalid_set's binary_logloss: 0.614963\tvalid_set's average_precision: 0.80359\n",
      "\tRan out of time, early stopping on iteration 20. Best iteration is:\n",
      "\t[20]\ttrain_set's binary_logloss: 0.616312\ttrain_set's average_precision: 0.809044\tvalid_set's binary_logloss: 0.61806\tvalid_set's average_precision: 0.800587\n",
      "\tRan out of time, early stopping on iteration 19. Best iteration is:\n",
      "\t[19]\ttrain_set's binary_logloss: 0.621704\ttrain_set's average_precision: 0.794695\tvalid_set's binary_logloss: 0.622277\tvalid_set's average_precision: 0.791896\n",
      "\tRan out of time, early stopping on iteration 17. Best iteration is:\n",
      "\t[17]\ttrain_set's binary_logloss: 0.62742\ttrain_set's average_precision: 0.79063\tvalid_set's binary_logloss: 0.629248\tvalid_set's average_precision: 0.784653\n",
      "\tRan out of time, early stopping on iteration 23. Best iteration is:\n",
      "\t[23]\ttrain_set's binary_logloss: 0.612014\ttrain_set's average_precision: 0.811228\tvalid_set's binary_logloss: 0.614264\tvalid_set's average_precision: 0.804316\n",
      "\tRan out of time, early stopping on iteration 28. Best iteration is:\n",
      "\t[28]\ttrain_set's binary_logloss: 0.600176\ttrain_set's average_precision: 0.830999\tvalid_set's binary_logloss: 0.60364\tvalid_set's average_precision: 0.820311\n",
      "\tRan out of time, early stopping on iteration 20. Best iteration is:\n",
      "\t[20]\ttrain_set's binary_logloss: 0.619173\ttrain_set's average_precision: 0.804364\tvalid_set's binary_logloss: 0.621637\tvalid_set's average_precision: 0.796243\n",
      "\tRan out of time, early stopping on iteration 13. Best iteration is:\n",
      "\t[13]\ttrain_set's binary_logloss: 0.63781\ttrain_set's average_precision: 0.764942\tvalid_set's binary_logloss: 0.638308\tvalid_set's average_precision: 0.765444\n",
      "\tRan out of time, early stopping on iteration 20. Best iteration is:\n",
      "\t[20]\ttrain_set's binary_logloss: 0.619449\ttrain_set's average_precision: 0.803839\tvalid_set's binary_logloss: 0.620668\tvalid_set's average_precision: 0.798825\n",
      "\t0.7959\t = Validation average_precision score\n",
      "\t42.68s\t = Training runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT_STACKER_l0 ... Training model for up to 0.77s of the 2155.87s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\ttrain_set's binary_logloss: 0.689561\ttrain_set's average_precision: 0.567784\tvalid_set's binary_logloss: 0.689741\tvalid_set's average_precision: 0.560729\n",
      "\tTime limit exceeded... Skipping LightGBMClassifierXT_STACKER_l0.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: weighted_ensemble_k0_l1 ... Training model for up to 360.0s of the 2152.81s of remaining time.\n",
      "\t0.9984\t = Validation average_precision score\n",
      "\t18.23s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l1 ... Training model for up to 2134.18s of the 2134.01s of remaining time.\n",
      "\t0.9984\t = Validation average_precision score\n",
      "\t801.14s\t = Training runtime\n",
      "\t9.06s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l1 ... Training model for up to 1321.79s of the 1321.62s of remaining time.\n",
      "\t0.9984\t = Validation average_precision score\n",
      "\t858.01s\t = Training runtime\n",
      "\t7.21s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l1 ... Training model for up to 454.32s of the 454.15s of remaining time.\n",
      "\t0.9984\t = Validation average_precision score\n",
      "\t180.05s\t = Training runtime\n",
      "\t7.28s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l1 ... Training model for up to 258.63s of the 258.46s of remaining time.\n",
      "\t0.9984\t = Validation average_precision score\n",
      "\t172.52s\t = Training runtime\n",
      "\t7.99s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l1 ... Training model for up to 70.05s of the 69.88s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTime limit exceeded... Skipping KNeighborsClassifierUnif_STACKER_l1.\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l1 ... Training model for up to 58.12s of the 57.95s of remaining time.\n",
      "\tTime limit exceeded... Skipping KNeighborsClassifierDist_STACKER_l1.\n",
      "Fitting model: LightGBMClassifier_STACKER_l1 ... Training model for up to 46.54s of the 46.37s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 6. Best iteration is:\n",
      "\t[6]\ttrain_set's binary_logloss: 0.334563\ttrain_set's average_precision: 0.997872\tvalid_set's binary_logloss: 0.334548\tvalid_set's average_precision: 0.997393\n",
      "\tRan out of time, early stopping on iteration 12. Best iteration is:\n",
      "\t[12]\ttrain_set's binary_logloss: 0.188744\ttrain_set's average_precision: 0.997978\tvalid_set's binary_logloss: 0.192103\tvalid_set's average_precision: 0.997533\n",
      "\tRan out of time, early stopping on iteration 25. Best iteration is:\n",
      "\t[24]\ttrain_set's binary_logloss: 0.0839523\ttrain_set's average_precision: 0.998114\tvalid_set's binary_logloss: 0.0846542\tvalid_set's average_precision: 0.998005\n",
      "\tRan out of time, early stopping on iteration 28. Best iteration is:\n",
      "\t[28]\ttrain_set's binary_logloss: 0.0698781\ttrain_set's average_precision: 0.998373\tvalid_set's binary_logloss: 0.0742752\tvalid_set's average_precision: 0.997993\n",
      "\tRan out of time, early stopping on iteration 22. Best iteration is:\n",
      "\t[22]\ttrain_set's binary_logloss: 0.0934253\ttrain_set's average_precision: 0.998035\tvalid_set's binary_logloss: 0.0944366\tvalid_set's average_precision: 0.998143\n",
      "\tRan out of time, early stopping on iteration 21. Best iteration is:\n",
      "\t[21]\ttrain_set's binary_logloss: 0.0987746\ttrain_set's average_precision: 0.998066\tvalid_set's binary_logloss: 0.100795\tvalid_set's average_precision: 0.998004\n",
      "\tRan out of time, early stopping on iteration 17. Best iteration is:\n",
      "\t[17]\ttrain_set's binary_logloss: 0.127966\ttrain_set's average_precision: 0.998023\tvalid_set's binary_logloss: 0.130145\tvalid_set's average_precision: 0.997793\n",
      "\tRan out of time, early stopping on iteration 25. Best iteration is:\n",
      "\t[25]\ttrain_set's binary_logloss: 0.0792976\ttrain_set's average_precision: 0.998179\tvalid_set's binary_logloss: 0.0859468\tvalid_set's average_precision: 0.997422\n",
      "\tRan out of time, early stopping on iteration 24. Best iteration is:\n",
      "\t[24]\ttrain_set's binary_logloss: 0.0841952\ttrain_set's average_precision: 0.99808\tvalid_set's binary_logloss: 0.0838531\tvalid_set's average_precision: 0.998282\n",
      "\tRan out of time, early stopping on iteration 38. Best iteration is:\n",
      "\t[38]\ttrain_set's binary_logloss: 0.0523777\ttrain_set's average_precision: 0.998605\tvalid_set's binary_logloss: 0.0548406\tvalid_set's average_precision: 0.998588\n",
      "\t0.9955\t = Validation average_precision score\n",
      "\t44.88s\t = Training runtime\n",
      "\t0.66s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT_STACKER_l1 ... Training model for up to 0.83s of the 0.66s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\ttrain_set's binary_logloss: 0.604094\ttrain_set's average_precision: 0.994521\tvalid_set's binary_logloss: 0.604144\tvalid_set's average_precision: 0.994127\n",
      "\tTime limit exceeded... Skipping LightGBMClassifierXT_STACKER_l1.\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: weighted_ensemble_k0_l2 ... Training model for up to 360.0s of the -2.35s of remaining time.\n",
      "\t0.9985\t = Validation average_precision score\n",
      "\t22.44s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4346.08s ...\n"
     ]
    }
   ],
   "source": [
    "time_limits = 1.2 * 60 *60\n",
    "predictor = task.fit(train_data=train, label=label_column, time_limits=time_limits, presets='best_quality', eval_metric='average_precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: average_precision on test data: 0.48184363966964505\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"average_precision\": 0.48184363966964505\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "perf = predictor.evaluate_predictions(y_true=test_targets, y_pred=prediction, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savetxt('predictions_{}_{}.csv'.format(label_type, coeff), prediction, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4610767262817508"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test[label_column])/len(test[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market_predictor",
   "language": "python",
   "name": "market_predictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
