{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1976"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Environments.BaseMarket import TestEnv\n",
    "from Environments.SimpleMarket import SimpleMarket\n",
    "\n",
    "from ray.rllib.agents.dqn.dqn import DQNTrainer, DEFAULT_CONFIG\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "import gym\n",
    "from ray.tune.registry import register_env\n",
    "import os\n",
    "import gc\n",
    "import torch \n",
    "import pandas as pd\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-09 14:35:21,631\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ray.init(num_gpus = 0, num_cpus = 4)\n",
    "except:\n",
    "    ray.shutdown()\n",
    "    ray.init(num_gpus = 0, num_cpus = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer_config = DEFAULT_CONFIG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_use_default_native_models': False,\n",
       " 'fcnet_hiddens': [256, 256],\n",
       " 'fcnet_activation': 'tanh',\n",
       " 'conv_filters': None,\n",
       " 'conv_activation': 'relu',\n",
       " 'post_fcnet_hiddens': [],\n",
       " 'post_fcnet_activation': 'relu',\n",
       " 'free_log_std': False,\n",
       " 'no_final_linear': False,\n",
       " 'vf_share_layers': True,\n",
       " 'use_lstm': False,\n",
       " 'max_seq_len': 20,\n",
       " 'lstm_cell_size': 256,\n",
       " 'lstm_use_prev_action': False,\n",
       " 'lstm_use_prev_reward': False,\n",
       " '_time_major': False,\n",
       " 'use_attention': False,\n",
       " 'attention_num_transformer_units': 1,\n",
       " 'attention_dim': 64,\n",
       " 'attention_num_heads': 1,\n",
       " 'attention_head_dim': 32,\n",
       " 'attention_memory_inference': 50,\n",
       " 'attention_memory_training': 50,\n",
       " 'attention_position_wise_mlp_dim': 32,\n",
       " 'attention_init_gru_gate_bias': 2.0,\n",
       " 'attention_use_n_prev_actions': 0,\n",
       " 'attention_use_n_prev_rewards': 0,\n",
       " 'num_framestacks': 'auto',\n",
       " 'dim': 84,\n",
       " 'grayscale': False,\n",
       " 'zero_mean': True,\n",
       " 'custom_model': None,\n",
       " 'custom_model_config': {},\n",
       " 'custom_action_dist': None,\n",
       " 'custom_preprocessor': None,\n",
       " 'lstm_use_prev_action_reward': -1,\n",
       " 'framestack': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config['model']['use_lstm'] = False\n",
    "trainer_config['model']['lstm_cell_size'] = 512\n",
    "trainer_config['num_gpus'] = 0\n",
    "trainer_config['num_gpus_per_worker'] = 0\n",
    "trainer_config['num_envs_per_worker'] = 1\n",
    "trainer_config['gamma'] = 0\n",
    "trainer_config['framework'] = 'torch'\n",
    "trainer_config['num_workers'] = 1\n",
    "trainer_config['horizon'] = 1000\n",
    "trainer_config['rollout_fragment_length'] = 1000\n",
    "trainer_config['model']['framestack'] = False\n",
    "trainer_config['model']['fcnet_hiddens'] = [1024, 1024]\n",
    "conf = {'curiosity_reward':0,\n",
    "        'continuous':False,\n",
    "        'data': 'Data/ground_truth/',\n",
    "        'starting_money': 1000,\n",
    "        'starting_stocks': 0,\n",
    "        'episode_length': 50,\n",
    "        'commission': 0.0025\n",
    "        }\n",
    "trainer_config['env_config'] = conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_env(env_config):\n",
    "    return TestEnv(SimpleMarket(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_env('SimpleMarket', create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-09 14:35:31,699\tINFO trainer.py:696 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2021-06-09 14:35:34,289\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m Stream name: -d77c5d22-b6f5-447f-a81a-e040b369bddc\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m Generator created\n"
     ]
    }
   ],
   "source": [
    "trainer = DQNTrainer(trainer_config, env = 'SimpleMarket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reward = -np.inf\n",
    "trainer.save()\n",
    "hall_of_fame = [0]\n",
    "last_checkpoint = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 0...\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 0      138.770000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 1        7.054754\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 2      138.750000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 3      138.750000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 4      138.800000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m           ...    \n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 245      0.000000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 246      0.000000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 247      0.000000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 248      0.000000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m 249      0.000000\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m Name: 0, Length: 250, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m Exception in thread Thread-1:\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m   File \"D:\\Program_files\\Anaconda\\envs\\ray\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m   File \"D:\\Projects\\hatchery\\perper\\samples\\PythonNotebook\\RL-Trader\\Environments\\BaseMarket.py\", line 29, in run\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m     observation = self.env.reset()\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m   File \"D:\\Projects\\hatchery\\perper\\samples\\PythonNotebook\\RL-Trader\\Environments\\SimpleMarket.py\", line 38, in reset\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m     state = super().reset()\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m   File \"D:\\Projects\\hatchery\\perper\\samples\\PythonNotebook\\RL-Trader\\Environments\\BaseMarket.py\", line 143, in reset\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m     self.current_price = state['price']\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m   File \"D:\\Program_files\\Anaconda\\envs\\ray\\lib\\site-packages\\pandas\\core\\series.py\", line 853, in __getitem__\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m     return self._get_value(key)\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m   File \"D:\\Program_files\\Anaconda\\envs\\ray\\lib\\site-packages\\pandas\\core\\series.py\", line 961, in _get_value\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m     loc = self.index.get_loc(label)\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m   File \"D:\\Program_files\\Anaconda\\envs\\ray\\lib\\site-packages\\pandas\\core\\indexes\\range.py\", line 354, in get_loc\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m     raise KeyError(key)\n",
      "\u001b[2m\u001b[36m(pid=17152)\u001b[0m KeyError: 'price'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    print(\"Training iteration {}...\".format(i))\n",
    "    results = trainer.train()\n",
    "    this_reward = results['episode_reward_max']\n",
    "    if this_reward > best_reward:\n",
    "        best_reward = this_reward\n",
    "        trainer.save()\n",
    "        path = trainer.logdir + 'checkpoint_{0}/checkpoint-{0}'.format(last_checkpoint)\n",
    "        os.remove(path)\n",
    "        last_checkpoint = i + 1\n",
    "        hall_of_fame.append(i+1)\n",
    "        print('New best reward')\n",
    "        print(best_reward)\n",
    "        \n",
    "    if i % 10 == 0:\n",
    "        print('Best Reward So Far')\n",
    "        print(best_reward)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(data=[[1, 3],[2, 4]], columns = [\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = trainer.logdir + 'checkpoint_{0}/checkpoint-{0}'.format(hall_of_fame[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(trainer.logdir + 'progress.csv')\n",
    "plt.plot(training['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = LimitMarket(conf)\n",
    "obs = env.reset()\n",
    "\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "prices = []\n",
    "assets = []\n",
    "actions = []\n",
    "states = [obs]\n",
    "rewards = []\n",
    "hidden = [torch.zeros(512),torch.zeros(512)]\n",
    "infos = []\n",
    "while not done:\n",
    "    action, hidden, info = trainer.compute_action(obs, hidden)\n",
    "    obs, reward, done, results = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    assets.append(results['assets'])\n",
    "    prices.append(results['current_price'])\n",
    "    states.append(obs)\n",
    "    infos.append(info)\n",
    "    if i % 100 == 0:\n",
    "        print('Step: {}/{}'.format(i, 200))\n",
    "print(\"Cumulative reward you've received is: {}. Congratulations!\".format(cumulative_reward))\n",
    "print(\"Asset_Gain {}\".format(assets[-1] -assets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_actions = []\n",
    "for action in actions:\n",
    "    pure_actions.append(action[0])\n",
    "    \n",
    "actions = pure_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy10 = np.ma.masked_where(np.array(actions) != 0, prices)\n",
    "buy20 = np.ma.masked_where(np.array(actions) != 1, prices)\n",
    "buy50 = np.ma.masked_where(np.array(actions) != 2, prices)\n",
    "sell10 = np.ma.masked_where(np.array(actions) != 3, prices)\n",
    "sell20 = np.ma.masked_where(np.array(actions) != 4, prices)\n",
    "sell50 = np.ma.masked_where(np.array(actions) != 5, prices)\n",
    "hold = np.ma.masked_where(np.array(actions) != 6, prices)\n",
    "\n",
    "# plt.plot(prices, marker = '', markersize = 0.5, markevery = np.where(np.array(actions) == 6, True, False))\n",
    "# plt.figure(figsize = (20, 15))\n",
    "# plt.plot(buy10, c = 'turquoise', linewidth = 0.6)\n",
    "# plt.plot(buy20, c = 'lime', linewidth = 0.6)\n",
    "# plt.plot(buy50, c = 'green', linewidth = 0.6)\n",
    "# plt.plot(hold, c = 'blue', linewidth = 0.6)\n",
    "graph_prices = prices[::10][:500]\n",
    "graph_actions = actions[::10][:500]\n",
    "colors = ['r', 'r', 'r', 'g', 'g', 'g', 'b']\n",
    "fig = plt.figure(figsize = (10, 6))\n",
    "plt.scatter(range(len(graph_prices)), graph_prices, s=1, color = np.array(colors)[graph_actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.test()\n",
    "\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "prices = []\n",
    "assets = []\n",
    "actions = []\n",
    "states = [obs]\n",
    "rewards = []\n",
    "hidden = [torch.zeros(512),torch.zeros(512)]\n",
    "infos = []\n",
    "market_beaters = []\n",
    "while not done:\n",
    "    action, hidden, info = trainer.compute_action(obs, hidden)\n",
    "    obs, reward, done, results = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    assets.append(results['assets'])\n",
    "    prices.append(results['current_price'])\n",
    "    states.append(obs)\n",
    "    infos.append(info)\n",
    "    market_beaters.append(results['market_beater'])\n",
    "print(\"Cumulative reward you've received is: {}. Congratulations!\".format(cumulative_reward))\n",
    "print(\"Asset_Gain {}\".format(assets[-1] -assets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(market_beaters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_actions = []\n",
    "for action in actions:\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy10 = np.ma.masked_where(np.array(actions) == 0, prices)\n",
    "buy20 = np.ma.masked_where(np.array(actions) == 1, prices)\n",
    "buy50 = np.ma.masked_where(np.array(actions) == 2, prices)\n",
    "hold = np.ma.masked_where(np.array(actions) == 3, prices)\n",
    "\n",
    "plt.plot(buy10, c = 'turquoise')\n",
    "plt.plot(buy20, c = 'lime')\n",
    "plt.plot(buy50, c = 'green')\n",
    "plt.plot(hold, c = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_beaters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_norm = preprocessing.normalize(np.array(prices).reshape(-1,1))\n",
    "assets_norm = preprocessing.normalize(np.array(assets).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_norm-prices_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
