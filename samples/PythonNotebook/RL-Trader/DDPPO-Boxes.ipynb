{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Environments.SineEnv import SineMarketEnv\n",
    "from Environments.BoxesMarket import BoxesMarket\n",
    "from Environments.wrappers.reward_wrapper import CuriosityWrapper\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "import gym\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents.ppo.ddppo import DEFAULT_CONFIG\n",
    "from ray.rllib.agents.ppo.ddppo import DDPPOTrainer\n",
    "import os\n",
    "import gc\n",
    "import torch \n",
    "import pandas as pd\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-30 21:45:58,641\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-10-30 21:45:58,650\tWARNING services.py:1617 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 66887680 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ray.init(num_gpus = 1, num_cpus = 4)\n",
    "except:\n",
    "    ray.shutdown()\n",
    "    ray.init(num_gpus = 1, num_cpus = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer_config = DEFAULT_CONFIG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fcnet_hiddens': [256, 256],\n",
       " 'fcnet_activation': 'tanh',\n",
       " 'conv_filters': None,\n",
       " 'conv_activation': 'relu',\n",
       " 'free_log_std': False,\n",
       " 'no_final_linear': False,\n",
       " 'vf_share_layers': True,\n",
       " 'use_lstm': False,\n",
       " 'max_seq_len': 20,\n",
       " 'lstm_cell_size': 256,\n",
       " 'lstm_use_prev_action_reward': False,\n",
       " '_time_major': False,\n",
       " 'framestack': True,\n",
       " 'dim': 84,\n",
       " 'grayscale': False,\n",
       " 'zero_mean': True,\n",
       " 'custom_model': None,\n",
       " 'custom_model_config': {},\n",
       " 'custom_action_dist': None,\n",
       " 'custom_preprocessor': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_config['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config['model']['use_lstm'] = False\n",
    "trainer_config['model']['lstm_cell_size'] = 512\n",
    "trainer_config['num_gpus'] = 0\n",
    "trainer_config['num_gpus_per_worker'] = 1\n",
    "trainer_config['num_envs_per_worker'] = 1\n",
    "trainer_config['gamma'] = 0\n",
    "trainer_config['entropy_coeff'] = 0\n",
    "trainer_config['framework'] = 'torch'\n",
    "trainer_config['num_workers'] = 1\n",
    "trainer_config['horizon'] = 1000\n",
    "trainer_config['rollout_fragment_length'] = 1000\n",
    "trainer_config['model']['framestack'] = False\n",
    "trainer_config['model']['fcnet_hiddens'] = [1024, 1024]\n",
    "conf = {'data': 'Data/predictions/',\n",
    "                                'starting_money': 1000,\n",
    "                                'starting_stocks': 0,\n",
    "                                'episode_length': 10000,\n",
    "                                'commission': 0.0025,\n",
    "                                'state_trades_num': 10,\n",
    "                                'action_mode':1,\n",
    "                                'curiosity_reward':0\n",
    "                                }\n",
    "trainer_config['env_config'] = conf\n",
    "trainer_config['entropy_coeff_schedule'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curiosity_env_create(env_config):\n",
    "    return CuriosityWrapper(BoxesMarket(env_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_env('CuriosityBoxesMarket', curiosity_env_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-30 21:45:58,986\tERROR syncer.py:63 -- Log sync requires rsync to be installed.\n",
      "2020-10-30 21:45:58,994\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m /root/miniconda3/envs/rl/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
      "2020-10-30 21:46:03,200\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "trainer = DDPPOTrainer(trainer_config, env = 'CuriosityBoxesMarket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reward = -np.inf\n",
    "trainer.save()\n",
    "hall_of_fame = [0]\n",
    "last_checkpoint = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 0...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rl/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  tensor = torch.from_numpy(np.asarray(item))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best reward\n",
      "5.526146333937678\n",
      "Best Reward So Far\n",
      "5.526146333937678\n",
      "Training iteration 1...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 2...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 3...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "New best reward\n",
      "17.741929108637805\n",
      "Training iteration 4...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "New best reward\n",
      "19.418306724177686\n",
      "Training iteration 5...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 6...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 7...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 8...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "New best reward\n",
      "24.3024467563592\n",
      "Training iteration 9...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "New best reward\n",
      "40.08108569376203\n",
      "Training iteration 10...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "40.08108569376203\n",
      "Training iteration 11...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "New best reward\n",
      "44.08481043057906\n",
      "Training iteration 12...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "New best reward\n",
      "68.27051707252876\n",
      "Training iteration 13...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 14...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 15...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 16...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 17...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 18...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 19...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 20...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "68.27051707252876\n",
      "Training iteration 21...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 22...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 23...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 24...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 25...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 26...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 27...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 28...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 29...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 30...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "68.27051707252876\n",
      "Training iteration 31...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 32...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 33...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 34...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 35...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 36...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 37...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 38...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "New best reward\n",
      "136.00294557275407\n",
      "Training iteration 39...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 40...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "136.00294557275407\n",
      "Training iteration 41...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 42...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 43...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 44...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 45...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 46...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 47...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 48...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 49...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 50...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "136.00294557275407\n",
      "Training iteration 51...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 52...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 53...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 54...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 55...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 56...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 57...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 58...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 59...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 60...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "136.00294557275407\n",
      "Training iteration 61...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 62...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 63...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 64...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 65...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 66...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 67...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 68...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 69...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 70...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "136.00294557275407\n",
      "Training iteration 71...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 72...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 73...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 74...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 75...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 76...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 77...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 78...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 79...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 80...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "136.00294557275407\n",
      "Training iteration 81...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 82...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 83...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 84...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 85...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 86...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 87...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 88...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 89...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 90...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Best Reward So Far\n",
      "136.00294557275407\n",
      "Training iteration 91...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 92...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "New best reward\n",
      "162.20156537078412\n",
      "Training iteration 93...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 94...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 95...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 96...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 97...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 98...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "Training iteration 99...\n",
      "\u001b[2m\u001b[36m(pid=11190)\u001b[0m ------------------------------Reset called------------------------------\n",
      "CPU times: user 24.9 s, sys: 6.94 s, total: 31.9 s\n",
      "Wall time: 10min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    print(\"Training iteration {}...\".format(i))\n",
    "    results = trainer.train()\n",
    "    this_reward = results['episode_reward_max']\n",
    "    if this_reward > best_reward:\n",
    "        best_reward = this_reward\n",
    "        trainer.save()\n",
    "        path = trainer.logdir + 'checkpoint_{0}/checkpoint-{0}'.format(last_checkpoint)\n",
    "        os.remove(path)\n",
    "        last_checkpoint = i + 1\n",
    "        hall_of_fame.append(i+1)\n",
    "        print('New best reward')\n",
    "        print(best_reward)\n",
    "    if i % 10 == 0:\n",
    "        print('Best Reward So Far')\n",
    "        print(best_reward)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = trainer.logdir + 'checkpoint_{0}/checkpoint-{0}'.format(hall_of_fame[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7d180a9160>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training = pd.read_csv(trainer.logdir + 'progress.csv')\n",
    "plt.plot(training['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Reset called------------------------------\n",
      "Cumulative reward you've received is: -0.0033574963987139175. Congratulations!\n",
      "Asset_Gain 50.95783641934872\n"
     ]
    }
   ],
   "source": [
    "env = BoxesMarket(conf)\n",
    "obs = env.reset()\n",
    "\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "prices = []\n",
    "assets = []\n",
    "actions = []\n",
    "states = [obs]\n",
    "rewards = []\n",
    "hidden = [torch.zeros(512),torch.zeros(512)]\n",
    "infos = []\n",
    "while not done:\n",
    "    action, hidden, info = trainer.compute_action(obs, hidden)\n",
    "    obs, reward, done, results = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    assets.append(results['assets'])\n",
    "    prices.append(results['current_price'])\n",
    "    states.append(obs)\n",
    "    infos.append(info)\n",
    "    if i % 100 == 0:\n",
    "        print('Step: {}/{}'.format(i, 200))\n",
    "print(\"Cumulative reward you've received is: {}. Congratulations!\".format(cumulative_reward))\n",
    "print(\"Asset_Gain {}\".format(assets[-1] -assets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4faeb4bac779>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpure_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpure_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpure_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "pure_actions = []\n",
    "for action in actions:\n",
    "    pure_actions.append(action[0])\n",
    "    \n",
    "actions = pure_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy10 = np.ma.masked_where(np.array(actions) != 0, prices)\n",
    "buy20 = np.ma.masked_where(np.array(actions) != 1, prices)\n",
    "buy50 = np.ma.masked_where(np.array(actions) != 2, prices)\n",
    "hold = np.ma.masked_where(np.array(actions) != 3, prices)\n",
    "\n",
    "plt.plot(buy10, c = 'turquoise')\n",
    "plt.plot(buy20, c = 'lime')\n",
    "plt.plot(buy50, c = 'green')\n",
    "plt.plot(hold, c = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.test()\n",
    "\n",
    "done = False\n",
    "cumulative_reward = 0\n",
    "prices = []\n",
    "assets = []\n",
    "actions = []\n",
    "states = [obs]\n",
    "rewards = []\n",
    "hidden = [torch.zeros(512),torch.zeros(512)]\n",
    "infos = []\n",
    "market_beaters = []\n",
    "while not done:\n",
    "    action, hidden, info = trainer.compute_action(obs, hidden)\n",
    "    obs, reward, done, results = env.step(action)\n",
    "    cumulative_reward += reward\n",
    "    rewards.append(reward)\n",
    "    actions.append(action)\n",
    "    assets.append(results['assets'])\n",
    "    prices.append(results['current_price'])\n",
    "    states.append(obs)\n",
    "    infos.append(info)\n",
    "    market_beaters.append(results['market_beater'])\n",
    "print(\"Cumulative reward you've received is: {}. Congratulations!\".format(cumulative_reward))\n",
    "print(\"Asset_Gain {}\".format(assets[-1] -assets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(market_beaters)\n",
    "plt.savefig(\"Graphics/market_beat_1.jpg\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_actions = []\n",
    "for action in actions:\n",
    "    pure_actions.append(action[0])\n",
    "    \n",
    "actions = pure_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy10 = np.ma.masked_where(np.array(actions) != 0, prices)\n",
    "buy20 = np.ma.masked_where(np.array(actions) != 1, prices)\n",
    "buy50 = np.ma.masked_where(np.array(actions) != 2, prices)\n",
    "hold = np.ma.masked_where(np.array(actions) != 3, prices)\n",
    "\n",
    "plt.plot(buy10, c = 'turquoise')\n",
    "plt.plot(buy20, c = 'lime')\n",
    "plt.plot(buy50, c = 'green')\n",
    "plt.plot(hold, c = 'blue')\n",
    "plt.savefig(\"Graphics/prices_1.jpg\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(assets)\n",
    "plt.savefig('Graphics/assets_1.jpg', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_beaters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_norm = preprocessing.normalize(np.array(prices).reshape(-1,1))\n",
    "assets_norm = preprocessing.normalize(np.array(assets).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_norm-prices_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
