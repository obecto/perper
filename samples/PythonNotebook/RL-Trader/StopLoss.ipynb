{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environments.StopLoss import StopLossMarket\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ray\n",
    "import gym\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.agents.ppo.ddppo import DEFAULT_CONFIG\n",
    "from ray.rllib.agents.ppo.ddppo import DDPPOTrainer\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-14 19:47:59,115\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
      "2020-10-14 19:47:59,121\tWARNING services.py:1617 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 66965504 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n",
      "2020-10-14 19:48:00,357\tERROR syncer.py:63 -- Log sync requires rsync to be installed.\n",
      "2020-10-14 19:48:00,363\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/root/miniconda3/envs/rl/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=13742)\u001b[0m /root/miniconda3/envs/rl/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=13742)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-10-14 19:48:03,710\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ray.init()\n",
    "trainer_config = DEFAULT_CONFIG.copy()\n",
    "trainer_config['model']['use_lstm'] = False\n",
    "trainer_config['model']['lstm_cell_size'] = 16\n",
    "trainer_config['num_gpus'] = 0\n",
    "trainer_config['num_gpus_per_worker'] = 1\n",
    "trainer_config['num_envs_per_worker'] = 8\n",
    "trainer_config['gamma'] = 0.99\n",
    "trainer_config['entropy_coeff'] = 0.00\n",
    "trainer_config['framework'] = 'torch'\n",
    "trainer_config['num_workers'] = 1\n",
    "trainer_config['horizon'] = 9999\n",
    "trainer_config['rollout_fragment_length'] = 9999\n",
    "trainer_config['model']['framestack'] = False\n",
    "trainer_config['model']['fcnet_hiddens'] = [128, 128, 128]\n",
    "trainer_config['lr'] = 15e-05\n",
    "trainer = DDPPOTrainer(trainer_config, StopLossMarket)\n",
    "best_reward = -np.inf\n",
    "trainer.save()\n",
    "hall_of_fame = [0]\n",
    "last_checkpoint = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13742)\u001b[0m /root/miniconda3/envs/rl/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "\u001b[2m\u001b[36m(pid=13742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iteration 0...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(40):\n",
    "    print(\"Training iteration {}...\".format(i))\n",
    "    results = trainer.train()\n",
    "    this_reward = results['episode_reward_max']\n",
    "    avg_reward = results['episode_reward_mean']\n",
    "    if this_reward > best_reward:\n",
    "        best_reward = this_reward\n",
    "        trainer.save()\n",
    "        path = trainer.logdir + 'checkpoint_{0}/checkpoint-{0}'.format(last_checkpoint)\n",
    "        os.remove(path)\n",
    "        last_checkpoint = i + 1\n",
    "        hall_of_fame.append(i+1)\n",
    "        print('New best reward') \n",
    "        print(best_reward)\n",
    "    if i % 10 == 0:\n",
    "        print('Best Reward So Far')\n",
    "        print(best_reward)\n",
    "        print('Average Rewards')\n",
    "        print(avg_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StopLossMarket(episode_length = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "for i in range(9999):\n",
    "    action = np.random.randint(2)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    if state[-1] != 0:\n",
    "        print(state[-1] * 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
